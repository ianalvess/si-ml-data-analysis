{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Notas para grupo:\n",
    "Este notebook precisa de um ficheiro \"dataset_reduced.csv\" resultante da secção \"Feature Reduction\" da section1.ipynb!\n",
    "\n",
    "O ficheiro \"dataset_reduced.csv\" trata-se do dataset preprocessado sem ter sido feito o train-test split.\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Supervised Learning\n",
    "# 1. Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.979618</td>\n",
       "      <td>-29.544092</td>\n",
       "      <td>-27.379373</td>\n",
       "      <td>26.890704</td>\n",
       "      <td>4.597509</td>\n",
       "      <td>-8.527948</td>\n",
       "      <td>-5.580079</td>\n",
       "      <td>-0.935693</td>\n",
       "      <td>-3.146765</td>\n",
       "      <td>-0.785730</td>\n",
       "      <td>...</td>\n",
       "      <td>3.648693</td>\n",
       "      <td>8.100660</td>\n",
       "      <td>-18.405698</td>\n",
       "      <td>10.772002</td>\n",
       "      <td>21.613432</td>\n",
       "      <td>9.607220</td>\n",
       "      <td>2.148750</td>\n",
       "      <td>-8.224677</td>\n",
       "      <td>-4.025757</td>\n",
       "      <td>7.693530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-18.060074</td>\n",
       "      <td>-29.511869</td>\n",
       "      <td>-27.561491</td>\n",
       "      <td>6.914117</td>\n",
       "      <td>4.454880</td>\n",
       "      <td>-16.256615</td>\n",
       "      <td>-5.189270</td>\n",
       "      <td>-14.303613</td>\n",
       "      <td>5.009351</td>\n",
       "      <td>0.124255</td>\n",
       "      <td>...</td>\n",
       "      <td>2.296746</td>\n",
       "      <td>-1.173271</td>\n",
       "      <td>-4.761234</td>\n",
       "      <td>-4.239881</td>\n",
       "      <td>15.279556</td>\n",
       "      <td>16.716698</td>\n",
       "      <td>1.232846</td>\n",
       "      <td>-0.798956</td>\n",
       "      <td>-4.019682</td>\n",
       "      <td>7.778053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-14.852828</td>\n",
       "      <td>-29.598422</td>\n",
       "      <td>-27.259799</td>\n",
       "      <td>29.207043</td>\n",
       "      <td>4.700565</td>\n",
       "      <td>-13.460366</td>\n",
       "      <td>-5.593262</td>\n",
       "      <td>10.941608</td>\n",
       "      <td>-10.088961</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>...</td>\n",
       "      <td>1.086670</td>\n",
       "      <td>-5.902036</td>\n",
       "      <td>-0.141581</td>\n",
       "      <td>-6.449239</td>\n",
       "      <td>15.141442</td>\n",
       "      <td>16.841146</td>\n",
       "      <td>1.028849</td>\n",
       "      <td>-10.111914</td>\n",
       "      <td>-4.086348</td>\n",
       "      <td>-1.198505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.399206</td>\n",
       "      <td>-29.478216</td>\n",
       "      <td>-27.583716</td>\n",
       "      <td>1.609595</td>\n",
       "      <td>4.401889</td>\n",
       "      <td>-2.826664</td>\n",
       "      <td>-6.029970</td>\n",
       "      <td>-8.969595</td>\n",
       "      <td>2.325586</td>\n",
       "      <td>0.041684</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500826</td>\n",
       "      <td>-1.728483</td>\n",
       "      <td>-5.257342</td>\n",
       "      <td>-3.038552</td>\n",
       "      <td>16.140339</td>\n",
       "      <td>15.780399</td>\n",
       "      <td>1.398832</td>\n",
       "      <td>-2.589509</td>\n",
       "      <td>-4.014831</td>\n",
       "      <td>2.595684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.928373</td>\n",
       "      <td>-29.722237</td>\n",
       "      <td>-27.613487</td>\n",
       "      <td>1.958608</td>\n",
       "      <td>4.503092</td>\n",
       "      <td>-0.188637</td>\n",
       "      <td>-6.238846</td>\n",
       "      <td>-3.589759</td>\n",
       "      <td>-1.220275</td>\n",
       "      <td>-0.108217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.827501</td>\n",
       "      <td>-2.511339</td>\n",
       "      <td>-3.766501</td>\n",
       "      <td>-2.098171</td>\n",
       "      <td>16.711619</td>\n",
       "      <td>15.528714</td>\n",
       "      <td>1.245762</td>\n",
       "      <td>-0.365768</td>\n",
       "      <td>-4.022382</td>\n",
       "      <td>-5.139971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3         4          5         6  \\\n",
       "0  -18.979618 -29.544092 -27.379373  26.890704  4.597509  -8.527948 -5.580079   \n",
       "1  -18.060074 -29.511869 -27.561491   6.914117  4.454880 -16.256615 -5.189270   \n",
       "2  -14.852828 -29.598422 -27.259799  29.207043  4.700565 -13.460366 -5.593262   \n",
       "3  -17.399206 -29.478216 -27.583716   1.609595  4.401889  -2.826664 -6.029970   \n",
       "4  100.928373 -29.722237 -27.613487   1.958608  4.503092  -0.188637 -6.238846   \n",
       "\n",
       "           7          8         9  ...        90        91         92  \\\n",
       "0  -0.935693  -3.146765 -0.785730  ...  3.648693  8.100660 -18.405698   \n",
       "1 -14.303613   5.009351  0.124255  ...  2.296746 -1.173271  -4.761234   \n",
       "2  10.941608 -10.088961 -0.000634  ...  1.086670 -5.902036  -0.141581   \n",
       "3  -8.969595   2.325586  0.041684  ...  1.500826 -1.728483  -5.257342   \n",
       "4  -3.589759  -1.220275 -0.108217  ...  1.827501 -2.511339  -3.766501   \n",
       "\n",
       "          93         94         95        96         97        98         Y  \n",
       "0  10.772002  21.613432   9.607220  2.148750  -8.224677 -4.025757  7.693530  \n",
       "1  -4.239881  15.279556  16.716698  1.232846  -0.798956 -4.019682  7.778053  \n",
       "2  -6.449239  15.141442  16.841146  1.028849 -10.111914 -4.086348 -1.198505  \n",
       "3  -3.038552  16.140339  15.780399  1.398832  -2.589509 -4.014831  2.595684  \n",
       "4  -2.098171  16.711619  15.528714  1.245762  -0.365768 -4.022382 -5.139971  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the pre-processed .csv file reduced by PCA\n",
    "data = pd.read_csv(\"dataset_reduced.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 21760 rows x 100 columns.\n",
      "Dataset has NaNs?: False\n",
      "\n",
      "Descriptive Statistics of target column 'Y':\n",
      "count    21760.000000\n",
      "mean         4.469692\n",
      "std         15.233728\n",
      "min        -36.459230\n",
      "25%         -5.206973\n",
      "50%          4.122120\n",
      "75%         13.840190\n",
      "max         45.956396\n",
      "Name: Y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verifying Dataset\n",
    "print(f\"Dataset shape: {data.shape[0]} rows x {data.shape[1]} columns.\")\n",
    "print(f\"Dataset has NaNs?: {data.isnull().values.any()}\")\n",
    "print(f\"\\nDescriptive Statistics of target column 'Y':\\n{data['Y'].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set \t Shape of X_train: (17408, 99) \n",
      "\t\t Shape of y_train: (17408,) \n",
      "\n",
      "Test Set \t Shape of X_test: (4352, 99) \n",
      "\t\t Shape of y_test: (4352,)\n"
     ]
    }
   ],
   "source": [
    "# Dataset splitting (random_state=42 for reproducible results)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('Y', axis=1)\n",
    "y = data['Y'] # Target column (y_true)\n",
    "\n",
    "# Split the dataset into training set (80%) and test set (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the shape of the resulting sets\n",
    "print(f'Training Set \\t Shape of X_train: {X_train.shape} \\n\\t\\t Shape of y_train: {y_train.shape} \\n')\n",
    "print(f'Test Set \\t Shape of X_test: {X_test.shape} \\n\\t\\t Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train and Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Ensures features are scaled appropriately. Procedure won't be necessary if data was already scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Multiple Models\n",
    "We will train and test the following models:\n",
    "\n",
    "- Ridge Regression (Linear + Regularization)\n",
    "- Random Forest Regressor (Ensemble)\n",
    "- KNeighbors Regressor (Instance-Based)\n",
    "- SVR (Kernel-Based)\n",
    "\n",
    "Future Models to Try Out\n",
    "- Gradient Boosting Algorithms (e.g., AdaBoost)\n",
    "\n",
    "\n",
    "We will evaluate our models using the following metrics:\n",
    "\n",
    "- Mean Squared Error (MSE):\n",
    "    - Measures the average squared difference between predicted and actual values.\n",
    "    - Penalizes larger errors more heavily, making it sensitive to outliers.\n",
    "\n",
    "- Mean Absolute Error (MAE):\n",
    "    - Measures the average absolute difference between predicted and actual values.\n",
    "    - Less sensitive to outliers compared to MSE, making it a robust metric for datasets with noise.\n",
    "\n",
    "- R-Squared (R²):\n",
    "    - Measures the proportion of variance in the target variable (`y_test`) explained by the model.\n",
    "    - A value closer to 1 indicates a better fit, while negative values suggest the model is worse than a simple mean prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing model: Ridge...\n",
      "Model: Ridge\n",
      "R2 Score: 0.2689\n",
      "MSE: 162.7323\n",
      "MAE: 9.8734\n",
      "------------------------------\n",
      "Training and Testing model: RandomForestRegressor...\n",
      "Model: RandomForestRegressor\n",
      "R2 Score: 0.3891\n",
      "MSE: 135.9684\n",
      "MAE: 8.8449\n",
      "------------------------------\n",
      "Training and Testing model: KNeighborsRegressor...\n",
      "Model: KNeighborsRegressor\n",
      "R2 Score: 0.2218\n",
      "MSE: 173.2008\n",
      "MAE: 10.1581\n",
      "------------------------------\n",
      "Training and Testing model: SVR...\n",
      "Model: SVR\n",
      "R2 Score: 0.3286\n",
      "MSE: 149.4378\n",
      "MAE: 9.3427\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train and Test multiple models\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    Ridge(random_state=42),                                                  \n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),  # n_jobs=-1 ensures all CPU cores are used. Model performance is not affected.\n",
    "    KNeighborsRegressor(),                                                \n",
    "    SVR()\n",
    "]\n",
    "\n",
    "# Initialize metrics list of each model for comparison\n",
    "metrics_summary = []\n",
    "\n",
    "# Iterate over models and calculate metrics\n",
    "for model in models:\n",
    "    # Indicate the current model being trained\n",
    "    print(f\"Training and Testing model: {model.__class__.__name__}...\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print metrics for the model\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"R2 Score: {test_r2:.4f}\")\n",
    "    print(f\"MSE: {test_mse:.4f}\")\n",
    "    print(f\"MAE: {test_mae:.4f}\")\n",
    "    print('-' * 30)\n",
    "\n",
    "    # Store metrics and model name\n",
    "    metrics_summary.append({\n",
    "        'model': model.__class__.__name__,\n",
    "        'r2_score': test_r2,\n",
    "        'mse': test_mse,\n",
    "        'mae': test_mae\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best R2 score: RandomForestRegressor\n",
      "R2 Score: 0.3891\n",
      "\n",
      "Model with best MSE: RandomForestRegressor\n",
      "MSE: 135.9684\n",
      "\n",
      "Model with best MAE: RandomForestRegressor\n",
      "MAE: 8.8449\n"
     ]
    }
   ],
   "source": [
    "# Determine the best model based on R2 Score (higher is better)\n",
    "best_model_r2 = max(metrics_summary, key=lambda x: x['r2_score'])\n",
    "\n",
    "# Optionally, determine the best model based on MSE or MAE (lower is better)\n",
    "best_model_mse = min(metrics_summary, key=lambda x: x['mse'])\n",
    "best_model_mae = min(metrics_summary, key=lambda x: x['mae'])\n",
    "\n",
    "# Print the best models\n",
    "print(f\"Model with best R2 score: {best_model_r2['model']}\\nR2 Score: {best_model_r2['r2_score']:.4f}\\n\")\n",
    "print(f\"Model with best MSE: {best_model_mse['model']}\\nMSE: {best_model_mse['mse']:.4f}\\n\")\n",
    "print(f\"Model with best MAE: {best_model_mae['model']}\\nMAE: {best_model_mae['mae']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Helps evaluate the stability and generalization performance of individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge, R2 values: [0.26766732 0.27259834 0.25769801 0.28889647 0.26831178], Mean R2: 0.2710343860540162\n",
      "Model: Ridge, Negative MSE values: [-170.50566765 -168.49895935 -172.30414435 -166.20581697 -176.8195474 ], Mean MSE: 170.86682714325048\n",
      "\n",
      "Model: RandomForestRegressor, R2 values: [0.38441029 0.38067843 0.36070431 0.38546648 0.37194625], Mean R2: 0.3766411514773342\n",
      "Model: RandomForestRegressor, Negative MSE values: [-143.32493528 -143.46274757 -148.39418233 -143.63456577 -151.77527473], Mean MSE: 146.11834113631272\n",
      "\n",
      "Model: KNeighborsRegressor, R2 values: [0.22187927 0.22797193 0.20883383 0.21216216 0.2310937 ], Mean R2: 0.2203881784181559\n",
      "Model: KNeighborsRegressor, Negative MSE values: [-181.16629143 -178.83644425 -183.64656279 -184.14088381 -185.81365785], Mean MSE: 182.72076802682483\n",
      "\n",
      "Model: SVR, R2 values: [0.31502942 0.31122598 0.29924214 0.32001121 0.30608552], Mean R2: 0.31031885153970457\n",
      "Model: SVR, Negative MSE values: [-159.47856776 -159.55106114 -162.66086455 -158.93338762 -167.69115877], Mean MSE: 161.66300796846642\n",
      "\n",
      "\n",
      "Summary of R2 scores: [0.2710343860540162, 0.3766411514773342, 0.2203881784181559, 0.31031885153970457]\n",
      "Summary of MSE: [170.86682714325048, 146.11834113631272, 182.72076802682483, 161.66300796846642]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize lists to store results\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "\n",
    "# Iterate through each model\n",
    "for model in models:\n",
    "    # R2 scores\n",
    "    r2 = cross_val_score(estimator=model, X=X_train, y=y_train, cv=5, scoring='r2')\n",
    "    r2_scores.append(r2.mean())\n",
    "    print(f\"Model: {model.__class__.__name__}, R2 values: {r2}, Mean R2: {r2.mean()}\")\n",
    "\n",
    "    # MSE scores\n",
    "    mse = cross_val_score(estimator=model, X=X_train, y=y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_scores.append(-mse.mean())  # Negate to get positive MSE\n",
    "    print(f\"Model: {model.__class__.__name__}, Negative MSE values: {mse}, Mean MSE: {-mse.mean()}\\n\")\n",
    "\n",
    "# Summary of results\n",
    "print(f\"\\nSummary of R2 scores: {r2_scores}\")\n",
    "print(f\"Summary of MSE: {mse_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Voting\n",
    "\n",
    "The ```VotingRegressor()``` combines the predictions from all included models. The metrics will reflect the aggregated performance of the ensemble of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Results:\n",
      "MSE: 139.30\n",
      "MAE: 9.07\n",
      "R2: 0.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Models to include in the ensemble\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('Ridge', Ridge()),\n",
    "    ('RandomForestRegression', RandomForestRegressor()),\n",
    "    ('KNeighborsRegressor', KNeighborsRegressor()),\n",
    "    ('SVR', SVR())\n",
    "])\n",
    "\n",
    "# Training the ensemble\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Perform the predictions using the ensemble\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble performance and print the results\n",
    "print(f\"Ensemble Results:\")\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred_ensemble):.2f}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred_ensemble):.2f}')\n",
    "print(f'R2: {r2_score(y_test, y_pred_ensemble):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is the process of systematically searching for the best combination of hyperparameters for a machine learning model to maximize its performance. Hyperparameters are configuration settings of the model that are not learned from the data but instead set prior to training, (e.g., number of estimators in a Random Forest).\n",
    "\n",
    "For this task we employed *scikit-learn*'s ```GridSearchCV()``` approach, which tests all possible combinations of specified hyperparameter values and evaluates their performance using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "MSE: 133.22\n",
      "MAE: 8.76\n",
      "R2 Score: 0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100], \n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4]\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42, n_jobs=-1), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_test, y_test)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_rf = best_model.predict(X_test)\n",
    "\n",
    "# Print the Best Parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print Best Metrics\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred_rf):.2f}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred_rf):.2f}')\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_rf):.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
